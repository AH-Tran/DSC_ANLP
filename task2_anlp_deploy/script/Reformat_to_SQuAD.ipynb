{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "\n",
    "# Read in training data as json \n",
    "jsonObj = pd.read_json(path_or_buf=\"../data/train.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "index_list = []\n",
    "\n",
    "# Identify abstractive spoiler and save their index in a list\n",
    "for i, j in jsonObj.iterrows():\n",
    "    string = \"\"\n",
    "    for k in j[\"targetParagraphs\"]:\n",
    "        string += k\n",
    "    for l in j[\"spoiler\"]:\n",
    "        if l not in string:\n",
    "            index_list.append(i)\n",
    "            counter +=1\n",
    "            \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop abstractive spoilers from training data\n",
    "\n",
    "jsonObj = jsonObj.drop(index=index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367\n"
     ]
    }
   ],
   "source": [
    "list_of_spoiler_dicts = []\n",
    "for i,j in jsonObj.iterrows():\n",
    "    \n",
    "    # Create dictionary for every spoiler\n",
    "    spoiler_dict = {}\n",
    "    \n",
    "    # Add Key-Value pair for title to the dictionary\n",
    "    spoiler_dict[\"title\"] = j[\"targetTitle\"]\n",
    "    \n",
    "    # Add Key-Value pair in the dictionary with a list for the multiple spoilers\n",
    "    spoiler_dict[\"paragraphs\"] = []\n",
    "    \n",
    "    # Dictionary with the metadata for the various spoilers in the spoiler text\n",
    "    paragraph_dict = {}\n",
    "    \n",
    "    # Add UUID of the spoiler as id to the corresponding paragraph\n",
    "    paragraph_dict[\"id\"] = j[\"uuid\"]\n",
    "    \n",
    "    # Create empty string to append all paragraphs and recreated the full context\n",
    "    context = \"\"\n",
    "    \n",
    "    # Recalculate the string position of the spoiler starts due to the recreating of the full context\n",
    "    offset = 0\n",
    "    counter = 0\n",
    "    \n",
    "    # Recreating the full context from the single paragraphs\n",
    "    for k in j[\"targetParagraphs\"]:\n",
    "        context += k + \" \"\n",
    "\n",
    "    \n",
    "    list_ans = []        \n",
    "    \n",
    "    dict_ans = {}\n",
    "    \n",
    "    # Add question/postText to the dictionary, that contains the answer\n",
    "    dict_ans[\"question\"] = j[\"postText\"][0]\n",
    "    \n",
    "    # Add UUID of the spoiler as id to the corresponding paragraph\n",
    "    dict_ans[\"id\"] = j[\"uuid\"]\n",
    "    \n",
    "    list_ans_2 = []\n",
    "    \n",
    "    for l in range(len(j[\"spoiler\"])):\n",
    "        \n",
    "        # Create dictionary for the answer metadata \n",
    "        dict_ans_2 = {}\n",
    "        \n",
    "        # Add the spoiler text to the \"text\" key in the dictionary\n",
    "        dict_ans_2[\"text\"] = j[\"spoiler\"][l]\n",
    "        \n",
    "        # Create variables to recreate the answer start position\n",
    "        offset = 0\n",
    "        counter = 0\n",
    "    \n",
    "        # Recalculate the answer start position in the full context\n",
    "        for k in j[\"targetParagraphs\"]:\n",
    "            if counter == j[\"spoilerPositions\"][l][0][0]:\n",
    "                break\n",
    "            offset += len(k) + 1\n",
    "            counter += 1\n",
    "            \n",
    "        \n",
    "        # Reformating the offset for the query start regarding the amount of whitespaces, that where added because of the recreation of the context\n",
    "        if len(j[\"spoilerPositions\"][l]) == 2:\n",
    "            if j[\"spoilerPositions\"][l][0][0] == j[\"spoilerPositions\"][l][1][0]:\n",
    "               \n",
    "                if context[j[\"spoilerPositions\"][l][0][1] + offset : j[\"spoilerPositions\"][l][0][1] + offset + len(j[\"spoiler\"][l])].startswith(\" \"):\n",
    "                    dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] + offset + 1\n",
    "                elif context[j[\"spoilerPositions\"][l][0][1] + offset : j[\"spoilerPositions\"][l][0][1] + offset + len(j[\"spoiler\"][l])].endswith(\" \"):\n",
    "                    dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] + offset + 2\n",
    "                else:\n",
    "                    dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] + offset\n",
    "            else:\n",
    "                dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] - 1\n",
    "\n",
    "        elif len(j[\"spoilerPositions\"][l]) == 1:\n",
    "            dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] \n",
    "\n",
    "        list_ans_2.append(dict_ans_2)\n",
    "        \n",
    "    \n",
    "    dict_ans[\"answers\"] = list_ans_2\n",
    "    \n",
    "    # Add the key-value pair for is_impossible. Always False, because abstrative spoiler were excluded beforehand \n",
    "    dict_ans[\"is_impossible\"] = False\n",
    "\n",
    "    \n",
    "    list_ans.append(dict_ans)\n",
    "    \n",
    "    # Creating dictionary that contains the context and the questions with the corresponding metadata\n",
    "    dict_qas_con = {}\n",
    "    \n",
    "    # Add questions and corresponding metadata like (answer_start) to the dictionary key \"qas\"\n",
    "    dict_qas_con[\"qas\"] = list_ans\n",
    "    \n",
    "    # Adding the full context to the dictionary\n",
    "    dict_qas_con[\"context\"] = context\n",
    "    spoiler_dict[\"paragraphs\"].append(dict_qas_con)\n",
    "   \n",
    "\n",
    "    list_of_spoiler_dicts.append(spoiler_dict)\n",
    "\n",
    "dict_final = {}\n",
    "\n",
    "# Add the version information to the json \n",
    "dict_final[\"version\"] = \"v2.0\"\n",
    "\n",
    "# Manually deleted spoilers, that cause issues\n",
    "\n",
    "##del list_of_spoiler_dicts[1767]\n",
    "##del list_of_spoiler_dicts[1703]\n",
    "#del list_of_spoiler_dicts[1633]\n",
    "#del list_of_spoiler_dicts[1632]\n",
    "#del list_of_spoiler_dicts[1631]\n",
    "#del list_of_spoiler_dicts[1630]\n",
    "#del list_of_spoiler_dicts[1629]\n",
    "#del list_of_spoiler_dicts[1628]\n",
    "#del list_of_spoiler_dicts[1600:1700]\n",
    "dict_final[\"data\"] = list_of_spoiler_dicts#[1628:1629]\n",
    "import json\n",
    "\n",
    "# Save Squad2.0 formatted training data as json \n",
    "with open('../data/train_squad_format_new_3.json', 'w') as fp:\n",
    "    json.dump(dict_final, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>postId</th>\n",
       "      <th>postText</th>\n",
       "      <th>postPlatform</th>\n",
       "      <th>targetParagraphs</th>\n",
       "      <th>targetTitle</th>\n",
       "      <th>targetDescription</th>\n",
       "      <th>targetKeywords</th>\n",
       "      <th>targetMedia</th>\n",
       "      <th>targetUrl</th>\n",
       "      <th>provenance</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>spoilerPositions</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0af11f6b-c889-4520-9372-66ba25cb7657</td>\n",
       "      <td>532quh</td>\n",
       "      <td>[Wes Welker Wanted Dinner With Tom Brady, But ...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>[It’ll be just like old times this weekend for...</td>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>It'll be just like old times this weekend for ...</td>\n",
       "      <td>new england patriots, ricky doyle, top stories,</td>\n",
       "      <td>[http://pixel.wp.com/b.gif?v=noscript, http://...</td>\n",
       "      <td>http://nesn.com/2016/09/wes-welker-wanted-dinn...</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'They...</td>\n",
       "      <td>[how about that morning we go throw?]</td>\n",
       "      <td>[[[3, 151], [3, 186]]]</td>\n",
       "      <td>[passage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b1a1f63d-8853-4a11-89e8-6b2952a393ec</td>\n",
       "      <td>411701128456593408</td>\n",
       "      <td>[NASA sets date for full recovery of ozone hole]</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[2070 is shaping up to be a great year for Mot...</td>\n",
       "      <td>Hole In Ozone Layer Expected To Make Full Reco...</td>\n",
       "      <td>2070 is shaping up to be a great year for Moth...</td>\n",
       "      <td>ozone layer,ozone hole determined by weather,M...</td>\n",
       "      <td>[http://s.m.huffpost.com/assets/Logo_Huffingto...</td>\n",
       "      <td>http://huff.to/1cH672Z</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': '2070...</td>\n",
       "      <td>[2070]</td>\n",
       "      <td>[[[0, 0], [0, 4]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008b7b19-0445-4e16-8f9e-075b73f80ca4</td>\n",
       "      <td>380537005123190784</td>\n",
       "      <td>[This is what makes employees happy -- and it'...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[Despite common belief, money isn't the key to...</td>\n",
       "      <td>Intellectual Stimulation Trumps Money For Empl...</td>\n",
       "      <td>By: Chad Brooks \\r\\nPublished: 09/18/2013 06:4...</td>\n",
       "      <td>employee happiness money,employee happiness in...</td>\n",
       "      <td>[http://i.huffpost.com/gen/1359674/images/o-HA...</td>\n",
       "      <td>http://huff.to/1epfeaw</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'Inte...</td>\n",
       "      <td>[intellectual stimulation]</td>\n",
       "      <td>[[[1, 186], [1, 210]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31ecf93c-3e21-4c80-949b-aa549a046b93</td>\n",
       "      <td>844567852531286016</td>\n",
       "      <td>[Passion is overrated — 7 work habits you need...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[It’s common wisdom. Near gospel really, and n...</td>\n",
       "      <td>‘Follow your passion’ is wrong, here are 7 hab...</td>\n",
       "      <td>There's a lot more to work that loving your job</td>\n",
       "      <td>business, work-life, careers</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': None,...</td>\n",
       "      <td>[Purpose connects us to something bigger and i...</td>\n",
       "      <td>[[[11, 25], [11, 101]], [[17, 56], [17, 85]], ...</td>\n",
       "      <td>[multi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31b108a3-c828-421a-a4b9-cf651e9ac859</td>\n",
       "      <td>814186311573766144</td>\n",
       "      <td>[The perfect way to cook rice so that it's per...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[Boiling rice may seem simple, but there is a ...</td>\n",
       "      <td>Revealed: The perfect way to cook rice so that...</td>\n",
       "      <td>The question 'How does one cook rice properly?...</td>\n",
       "      <td>Quora,users,share,perfect,way,cook,rice</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': None,...</td>\n",
       "      <td>[in a rice cooker]</td>\n",
       "      <td>[[[5, 60], [5, 76]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>92578045-699f-4957-a3c5-cff2c3874dae</td>\n",
       "      <td>591979258442027008</td>\n",
       "      <td>[Has Facebook's video explosion completely sha...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[A long time ago in a galaxy far, far away...W...</td>\n",
       "      <td>Facebook Video Surging, But YouTube Still Offe...</td>\n",
       "      <td>.</td>\n",
       "      <td>Facebook,web video,web video ads,YouTube</td>\n",
       "      <td>[http://djcs-prod.s3.amazonaws.com/wsjfrontpag...</td>\n",
       "      <td>http://on.wsj.com/1GfyUqz</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'No.'...</td>\n",
       "      <td>[it hasn’t necessarily taken the wind out of Y...</td>\n",
       "      <td>[[[7, 50], [7, 118]]]</td>\n",
       "      <td>[passage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>51682121-df0b-4289-a95f-e1bc3d181306</td>\n",
       "      <td>881531941974661_902284433232745</td>\n",
       "      <td>[Cop Is Eating At A Chili's When Teen Hands Hi...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>[The Kansas City, Kansas Police Department are...</td>\n",
       "      <td>Cop is eating at Chili's when teen hands him f...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://sbly-web-prod-shareably.netdna-ssl.co...</td>\n",
       "      <td>http://shareably.net/officer-receives-touching...</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'The ...</td>\n",
       "      <td>[It read, \"Thanks for keeping us safe.\"]</td>\n",
       "      <td>[[[0, 317], [0, 355]]]</td>\n",
       "      <td>[passage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>9c45ca67-38c4-47b4-aa0d-48434bae09fc</td>\n",
       "      <td>837356193576333314</td>\n",
       "      <td>[5 popular myths about visible signs of aging ...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[Obama looks decades younger already, but what...</td>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>Dozens of anti-wrinkle products and creams are...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.businessinsider.in/5-popular-myths...</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': None,...</td>\n",
       "      <td>[1. Anti-wrinkle creams will erase the fine li...</td>\n",
       "      <td>[[[6, 0], [6, 73]], [[10, 0], [10, 109]], [[14...</td>\n",
       "      <td>[multi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>9d05984c-3920-47c0-aa97-8df58cca1fec</td>\n",
       "      <td>826912122529521666</td>\n",
       "      <td>[You need to see this Twitter account that pre...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[What the HELL?!, 1. Unless you’re somewhere w...</td>\n",
       "      <td>WTF, It Looks Like This Twitter Account \"Predi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': None,...</td>\n",
       "      <td>[@beyoncefan666]</td>\n",
       "      <td>[[[3, 55], [3, 69]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>0d9e3a31-77f7-414a-9d70-5213f2c0cd94</td>\n",
       "      <td>471834972652048385</td>\n",
       "      <td>[GOP congressman comes out for gay marriage]</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.) came out in support...</td>\n",
       "      <td>Pennsylvania GOP Rep. Charlie Dent Comes Out F...</td>\n",
       "      <td>Rep. Charlie Dent (R-Pa.)</td>\n",
       "      <td>lgbt,charlie dent gay marriage,Charlie Dent,pe...</td>\n",
       "      <td>[http://s.m.huffpost.com/assets/Logo_Huffingto...</td>\n",
       "      <td>http://huff.to/1kMAadJ</td>\n",
       "      <td>{'source': 'anonymized', 'humanSpoiler': 'Rep....</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.)]</td>\n",
       "      <td>[[[0, 0], [0, 25]]]</td>\n",
       "      <td>[phrase]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      uuid                           postId  \\\n",
       "0     0af11f6b-c889-4520-9372-66ba25cb7657                           532quh   \n",
       "1     b1a1f63d-8853-4a11-89e8-6b2952a393ec               411701128456593408   \n",
       "2     008b7b19-0445-4e16-8f9e-075b73f80ca4               380537005123190784   \n",
       "3     31ecf93c-3e21-4c80-949b-aa549a046b93               844567852531286016   \n",
       "4     31b108a3-c828-421a-a4b9-cf651e9ac859               814186311573766144   \n",
       "...                                    ...                              ...   \n",
       "3195  92578045-699f-4957-a3c5-cff2c3874dae               591979258442027008   \n",
       "3196  51682121-df0b-4289-a95f-e1bc3d181306  881531941974661_902284433232745   \n",
       "3197  9c45ca67-38c4-47b4-aa0d-48434bae09fc               837356193576333314   \n",
       "3198  9d05984c-3920-47c0-aa97-8df58cca1fec               826912122529521666   \n",
       "3199  0d9e3a31-77f7-414a-9d70-5213f2c0cd94               471834972652048385   \n",
       "\n",
       "                                               postText postPlatform  \\\n",
       "0     [Wes Welker Wanted Dinner With Tom Brady, But ...       reddit   \n",
       "1      [NASA sets date for full recovery of ozone hole]      Twitter   \n",
       "2     [This is what makes employees happy -- and it'...      Twitter   \n",
       "3     [Passion is overrated — 7 work habits you need...      Twitter   \n",
       "4     [The perfect way to cook rice so that it's per...      Twitter   \n",
       "...                                                 ...          ...   \n",
       "3195  [Has Facebook's video explosion completely sha...      Twitter   \n",
       "3196  [Cop Is Eating At A Chili's When Teen Hands Hi...     Facebook   \n",
       "3197  [5 popular myths about visible signs of aging ...      Twitter   \n",
       "3198  [You need to see this Twitter account that pre...      Twitter   \n",
       "3199       [GOP congressman comes out for gay marriage]      Twitter   \n",
       "\n",
       "                                       targetParagraphs  \\\n",
       "0     [It’ll be just like old times this weekend for...   \n",
       "1     [2070 is shaping up to be a great year for Mot...   \n",
       "2     [Despite common belief, money isn't the key to...   \n",
       "3     [It’s common wisdom. Near gospel really, and n...   \n",
       "4     [Boiling rice may seem simple, but there is a ...   \n",
       "...                                                 ...   \n",
       "3195  [A long time ago in a galaxy far, far away...W...   \n",
       "3196  [The Kansas City, Kansas Police Department are...   \n",
       "3197  [Obama looks decades younger already, but what...   \n",
       "3198  [What the HELL?!, 1. Unless you’re somewhere w...   \n",
       "3199  [Rep. Charlie Dent (R-Pa.) came out in support...   \n",
       "\n",
       "                                            targetTitle  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1     Hole In Ozone Layer Expected To Make Full Reco...   \n",
       "2     Intellectual Stimulation Trumps Money For Empl...   \n",
       "3     ‘Follow your passion’ is wrong, here are 7 hab...   \n",
       "4     Revealed: The perfect way to cook rice so that...   \n",
       "...                                                 ...   \n",
       "3195  Facebook Video Surging, But YouTube Still Offe...   \n",
       "3196  Cop is eating at Chili's when teen hands him f...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  WTF, It Looks Like This Twitter Account \"Predi...   \n",
       "3199  Pennsylvania GOP Rep. Charlie Dent Comes Out F...   \n",
       "\n",
       "                                      targetDescription  \\\n",
       "0     It'll be just like old times this weekend for ...   \n",
       "1     2070 is shaping up to be a great year for Moth...   \n",
       "2     By: Chad Brooks \\r\\nPublished: 09/18/2013 06:4...   \n",
       "3       There's a lot more to work that loving your job   \n",
       "4     The question 'How does one cook rice properly?...   \n",
       "...                                                 ...   \n",
       "3195                                                  .   \n",
       "3196                                               None   \n",
       "3197  Dozens of anti-wrinkle products and creams are...   \n",
       "3198                                                      \n",
       "3199                          Rep. Charlie Dent (R-Pa.)   \n",
       "\n",
       "                                         targetKeywords  \\\n",
       "0       new england patriots, ricky doyle, top stories,   \n",
       "1     ozone layer,ozone hole determined by weather,M...   \n",
       "2     employee happiness money,employee happiness in...   \n",
       "3                          business, work-life, careers   \n",
       "4               Quora,users,share,perfect,way,cook,rice   \n",
       "...                                                 ...   \n",
       "3195           Facebook,web video,web video ads,YouTube   \n",
       "3196                                               None   \n",
       "3197                                                      \n",
       "3198                                                      \n",
       "3199  lgbt,charlie dent gay marriage,Charlie Dent,pe...   \n",
       "\n",
       "                                            targetMedia  \\\n",
       "0     [http://pixel.wp.com/b.gif?v=noscript, http://...   \n",
       "1     [http://s.m.huffpost.com/assets/Logo_Huffingto...   \n",
       "2     [http://i.huffpost.com/gen/1359674/images/o-HA...   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "3195  [http://djcs-prod.s3.amazonaws.com/wsjfrontpag...   \n",
       "3196  [https://sbly-web-prod-shareably.netdna-ssl.co...   \n",
       "3197                                               None   \n",
       "3198                                               None   \n",
       "3199  [http://s.m.huffpost.com/assets/Logo_Huffingto...   \n",
       "\n",
       "                                              targetUrl  \\\n",
       "0     http://nesn.com/2016/09/wes-welker-wanted-dinn...   \n",
       "1                                http://huff.to/1cH672Z   \n",
       "2                                http://huff.to/1epfeaw   \n",
       "3                                                  None   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "3195                          http://on.wsj.com/1GfyUqz   \n",
       "3196  http://shareably.net/officer-receives-touching...   \n",
       "3197  https://www.businessinsider.in/5-popular-myths...   \n",
       "3198                                               None   \n",
       "3199                             http://huff.to/1kMAadJ   \n",
       "\n",
       "                                             provenance  \\\n",
       "0     {'source': 'anonymized', 'humanSpoiler': 'They...   \n",
       "1     {'source': 'anonymized', 'humanSpoiler': '2070...   \n",
       "2     {'source': 'anonymized', 'humanSpoiler': 'Inte...   \n",
       "3     {'source': 'anonymized', 'humanSpoiler': None,...   \n",
       "4     {'source': 'anonymized', 'humanSpoiler': None,...   \n",
       "...                                                 ...   \n",
       "3195  {'source': 'anonymized', 'humanSpoiler': 'No.'...   \n",
       "3196  {'source': 'anonymized', 'humanSpoiler': 'The ...   \n",
       "3197  {'source': 'anonymized', 'humanSpoiler': None,...   \n",
       "3198  {'source': 'anonymized', 'humanSpoiler': None,...   \n",
       "3199  {'source': 'anonymized', 'humanSpoiler': 'Rep....   \n",
       "\n",
       "                                                spoiler  \\\n",
       "0                 [how about that morning we go throw?]   \n",
       "1                                                [2070]   \n",
       "2                            [intellectual stimulation]   \n",
       "3     [Purpose connects us to something bigger and i...   \n",
       "4                                    [in a rice cooker]   \n",
       "...                                                 ...   \n",
       "3195  [it hasn’t necessarily taken the wind out of Y...   \n",
       "3196           [It read, \"Thanks for keeping us safe.\"]   \n",
       "3197  [1. Anti-wrinkle creams will erase the fine li...   \n",
       "3198                                   [@beyoncefan666]   \n",
       "3199                        [Rep. Charlie Dent (R-Pa.)]   \n",
       "\n",
       "                                       spoilerPositions       tags  \n",
       "0                                [[[3, 151], [3, 186]]]  [passage]  \n",
       "1                                    [[[0, 0], [0, 4]]]   [phrase]  \n",
       "2                                [[[1, 186], [1, 210]]]   [phrase]  \n",
       "3     [[[11, 25], [11, 101]], [[17, 56], [17, 85]], ...    [multi]  \n",
       "4                                  [[[5, 60], [5, 76]]]   [phrase]  \n",
       "...                                                 ...        ...  \n",
       "3195                              [[[7, 50], [7, 118]]]  [passage]  \n",
       "3196                             [[[0, 317], [0, 355]]]  [passage]  \n",
       "3197  [[[6, 0], [6, 73]], [[10, 0], [10, 109]], [[14...    [multi]  \n",
       "3198                               [[[3, 55], [3, 69]]]   [phrase]  \n",
       "3199                                [[[0, 0], [0, 25]]]   [phrase]  \n",
       "\n",
       "[3200 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read in validation dataset\n",
    "with open('../data/validation.jsonl', 'r', encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform validation dataset dictionary into pandas dataframe \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "index_list = []\n",
    "\n",
    "# Identify abstractive spoiler and save their index in a list\n",
    "for i, j in df.iterrows():\n",
    "    string = \"\"\n",
    "    for k in j[\"targetParagraphs\"]:\n",
    "        string += k\n",
    "    for l in j[\"spoiler\"]:\n",
    "        if l not in string:\n",
    "            index_list.append(i)\n",
    "            counter +=1\n",
    "            \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop abstractive spoilers from validation data\n",
    "\n",
    "df = df.drop(index=index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the validation dataset into Squad2.0 format is similar to the transformation of the training dataset above\n",
    "# Therefore the documentation is also the same\n",
    "\n",
    "list_of_spoiler_dicts = []\n",
    "for i,j in df.iterrows():\n",
    "\n",
    "    spoiler_dict = {}\n",
    "    \n",
    "\n",
    "    spoiler_dict[\"title\"] = j[\"targetTitle\"]\n",
    "    \n",
    "\n",
    "    spoiler_dict[\"paragraphs\"] = []\n",
    "    paragraph_dict = {}\n",
    "    \n",
    "    paragraph_dict[\"id\"] = j[\"uuid\"]\n",
    "    \n",
    "    context = \"\"\n",
    "    offset = 0\n",
    "    counter = 0\n",
    "    for k in j[\"targetParagraphs\"]:\n",
    "        context += k + \" \"\n",
    "\n",
    "    \n",
    "    list_ans = []        \n",
    "    dict_ans = {}\n",
    "    dict_ans[\"question\"] = j[\"postText\"][0]\n",
    "    dict_ans[\"id\"] = j[\"uuid\"]\n",
    "    list_ans_2 = []\n",
    "    for l in range(len(j[\"spoiler\"])):\n",
    "        dict_ans_2 = {}\n",
    "        dict_ans_2[\"text\"] = j[\"spoiler\"][l]\n",
    "        offset = 0\n",
    "        counter = 0\n",
    "       \n",
    "        for k in j[\"targetParagraphs\"]:\n",
    "            if counter == j[\"spoilerPositions\"][l][0][0]:\n",
    "                break\n",
    "            offset += len(k) + 1\n",
    "            counter += 1\n",
    "            \n",
    "     \n",
    "        if len(j[\"spoilerPositions\"][l]) == 2:\n",
    "            if j[\"spoilerPositions\"][l][0][0] == j[\"spoilerPositions\"][l][1][0]:\n",
    "               \n",
    "                if context[j[\"spoilerPositions\"][l][0][1] + offset : j[\"spoilerPositions\"][l][0][1] + offset + len(j[\"spoiler\"][l])].startswith(\" \"):\n",
    "                    dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] + offset + 1\n",
    "                elif context[j[\"spoilerPositions\"][l][0][1] + offset : j[\"spoilerPositions\"][l][0][1] + offset + len(j[\"spoiler\"][l])].endswith(\" \"):\n",
    "                    dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] + offset + 2\n",
    "                else:\n",
    "                    dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] + offset\n",
    "            else:\n",
    "                dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] - 1\n",
    "\n",
    "        elif len(j[\"spoilerPositions\"][l]) == 1:\n",
    "            dict_ans_2[\"answer_start\"] = j[\"spoilerPositions\"][l][0][1] \n",
    "\n",
    "     \n",
    "        list_ans_2.append(dict_ans_2)\n",
    "        \n",
    "    \n",
    "    dict_ans[\"answers\"] = list_ans_2\n",
    "    dict_ans[\"is_impossible\"] = False\n",
    "\n",
    "    \n",
    "    list_ans.append(dict_ans)\n",
    "    dict_qas_con = {}\n",
    "    dict_qas_con[\"qas\"] = list_ans\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dict_qas_con[\"context\"] = context\n",
    "    spoiler_dict[\"paragraphs\"].append(dict_qas_con)\n",
    "   \n",
    "\n",
    "    list_of_spoiler_dicts.append(spoiler_dict)\n",
    "\n",
    "dict_final = {}\n",
    "dict_final[\"version\"] = \"v2.0\"\n",
    "\n",
    "#del list_of_spoiler_dicts[1600:1700]\n",
    "#del list_of_spoiler_dicts[731]\n",
    "del list_of_spoiler_dicts[650:750]\n",
    "dict_final[\"data\"] = list_of_spoiler_dicts#[:750]\n",
    "import json\n",
    "\n",
    "with open('../data/val_squad_format_new.json', 'w') as fp:\n",
    "    json.dump(dict_final, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
